{"custom_id": "unified_1255447", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-5-mini-2025-08-07", "messages": [{"role": "system", "content": "Based on this resume, give the user the information they need: \n# Chandana Burugu\nPh: (+1) Gmail: \u2022 Phone: 913-703-5848 \u2022 Email: bchandana.2720@gmail.com\n\n**Linkedlin** | Senior. NET Developer\n\n## Summary\n* Senior. NET Developer with over 8 years of experience specializing in full lifecycle software development.\n* Engineered scalable. NET applications utilizing C#, Core, and MVC frameworks, significantly enhancing functionality across multiple projects.\n* Developed robust backend solutions using Entity Framework and MS NET SQL Server, improving data integrity and query performance.\n* Integrated Azure services for cloud deployments, effectively managing resources and ensuring high availability of applications.\n* Employed Visual Studio and Jet Brains Rider as primary development environments, enhancing productivity and streamlining the coding process.\n* Implemented comprehensive unit and integration testing using NUnit and MSTest, ensuring the reliability and stability of software products.\n* Designed and deployed dynamic web interfaces using Blazor and Angular, providing users with interactive and responsive experiences.\n* Leveraged AWS Lambda and Amazon RDS to create scalable, serverless backend architectures that reduced operational costs and improved efficiency.\n* Utilized Docker for containerization, simplifying configuration and deployment across various environments and enhancing consistency.\n* Managed version control and continuous integration/continuous deployment (CI/CD) using Azure DevOps, improving team collaboration and deployment speed.\n* Developed secure web applications by implementing industry-standard security practices and protocols to protect data and prevent breaches.\n* Coordinated with cross-functional teams to translate business requirements into technical specifications, ensuring alignment with strategic goals.\n* Conducted code reviews and maintained high coding standards, fostering a culture of excellence and continuous improvement within development teams.\n* Utilized Agile methodologies to manage project lifecycles, enhancing team flexibility and responsiveness to change.\n* Architected database solutions using Dapper and Entity Framework, streamlining data access and manipulation for complex business applications.\n* Enhanced user experience by implementing modern UI/UX design principles in web development projects, resulting in increased user engagement and satisfaction.\n* Configured and maintained cloud environments using Azure Functions and Cosmos DB, optimizing storage and data processing capabilities.\n* Provided technical leadership and guidance to junior developers, promoting professional growth and development within the team.\n* Developed and maintained comprehensive documentation for software projects, facilitating knowledge sharing and future maintenance efforts.\n* Utilized JIRA and Confluence for project management and documentation, enhancing team communication and project tracking.\n* Actively participated in community forums and technical discussions, contributing to the broader tech community, and enhancing personal knowledge.\n* Hands-on experience with serverless computing, leveraging AWS Lambda, Azure Functions, and Google Cloud Functions for cost-effective and scalable solutions.\n* Proficient in Graph QL for optimizing data retrieval, reducing API over-fetching and under-fetching issues.\n* Experienced in real-time application development using Web Sockets and Signal R, enabling features like live notifications and chat functionality.\n* Skilled in performance optimization of. NET applications, utilizing tools such as dot Trace and Application Insights to enhance efficiency.\n* Expertise in designing and implementing RESTful APIs, adhering to industry best practices like HATEOAS and Open API standards.\n* Hands-on experience in data warehousing and ETL processes, using Azure Synapse Analytics and AWS Glue for large-scale data management.\n* Strong expertise in database sharding and replication strategies, optimizing performance and scalability for high-traffic applications.\n* Experience in real-time analytics and event sourcing using Apache Kafka Streams and Azure Event Hubs for large-scale data processing.\n\n## Skills\n\nLanguage\tC#, VB. NET, C++, C, SQL.\nFrameworks & Libraries NET Framework 4.8/4.6/4.5,. NET Core 8.0/6.0/2.1/2.0, C# ASP. NET Core Web API, ASP. NET MVC 5, ADO. NET, Entity Framework Core 8/6/2.2, Dapper, LINQ, Razor Pages, AJAX, Blazor, VB. NET, Microservices.\n\nFrontend Technologies\tAngular, React, Blazor, Vue. js, Razor Pages Development Tools\tVisual Studio, Jet Brains Rider, Visual Studio Code Web/Application Server\tInternet Information Services, Kestrel, Nginx Database\tMS SQL Server, Azure Cosmos DB, Amazon RDS, MySQL, PostgreSQL Methodologies\tAgile, Scrum, CI/CD Build Tools\t Azure DevOps, Git, JIRA, GitHub, GitHub Actions, Jenkins Testing & CI/CD\tNUnit, MSTest, Autofac,. NET Core DI, Moq, XUnit, Postman Cloud Platforms & Services Azure Functions, Azure Cosmos DB, AWS Lambda, Azure DevOps, Amazon RDS, Docker, Kubernetes Web Technologies\tHTML, DHTML, CSS, Angular, Bootstrap, JSON, jQuery, Ajax, Node JS, React\n\n## Experience\n\nClient: Vertex, Cerritos, CA\tDec 2023 - Present\nRole: Sr. Net developer Responsibilities:\n* Developed enterprise healthcare applications using C# and. NET 8, enhancing system capabilities and user accessibility\n* Integrated Azure Cosmos DB and SQL Server for data storage solutions, optimizing data retrieval and storage efficiency in cloud-based environments.\n* Employed Azure Functions for serverless computing, enabling more agile development and deployment processes for healthcare applications.\n* Utilized NUnit for rigorous testing frameworks, ensuring that all new and existing features met the highest standards of quality.\n* Built interactive web UIs using Blazor and Angular 17, enhancing patient and provider engagement.\n* Configured Kestrel web server as part of the core technology stack, optimizing web hosting and request processing.\n* Developed robust CI/CD pipelines using Azure DevOps, ensuring seamless transitions from development to production environments.\n* Conducted detailed code reviews and performance optimizations, enhancing application efficiency and reducing runtime errors.\n* Implemented secure data access and protection protocols using Azure security tools, safeguarding patient data against breaches.\n* Collaborated with healthcare professionals to tailor applications to specific medical workflows, ensuring usability and compliance.\n* Architected solutions that supported high availability and disaster recovery strategies, guaranteeing uptime and data integrity.\n* Facilitated cloud migration strategies for legacy healthcare systems, employing Azure Cosmos DB and Azure Functions to ensure a smooth transition.\n* Employed modern frontend technologies to enhance cross-platform accessibility, improving access on mobile and desktop devices.\n* Enabled real-time updates for healthcare providers using Signal R and Angular 17.\n* Optimized database performance using advanced querying and indexing strategies, ensuring fast access to large volumes of healthcare data.\n* Implemented automated testing strategies using NUnit, enhancing the reliability and stability of healthcare applications.\n* Developed API integrations using. NET 8, enabling seamless connections with other healthcare systems and third-party services.\n* Conducted training sessions for end-users and internal teams, enhancing their ability to effectively utilize the new healthcare applications.\nEnvironment: C#,. NET 8, Angular 1Azure Cosmos DB, Azure Functions, NUnit, Blazor, Vue. js, Kestrel, Visual Studio 2017, Azure DevOps, Signal R, Angular, Dependency Injection, Azure security tools, and API integrations.\n* Client: Met Life, Louisville, KY\tJan 2022 - Dec 2023 Role:. Net developer Responsibilities:\n* Developed robust insurance applications leveraging C# and. NET 8, streamlining claims processing and customer service operations.\n* Utilized Razor Pages to simplify the construction of complex UIs, enhancing user interaction and responsiveness.\n* Implemented Dapper for efficient data management, optimizing database interactions and reducing overhead.\n* Configured AWS Lambda to handle serverless computing needs, significantly reducing infrastructure costs and improving scalability.\n* Employed NUnit for comprehensive testing across all development stages, ensuring high reliability and adherence to business requirements.\n* Built dynamic front-end applications using Angular 17, improving overall user experience and engagement.\n* Managed application deployment using Amazon RDS and Nginx, ensuring efficient load handling and data security.\n* Leveraged Azure Functions and Cosmos DB to enhance cloud-based data processing and scalability.\n* Utilized Azure DevOps for CI/CD pipelines, automating deployment processes and improving operational efficiency\n* Conducted performance tuning and optimization to meet high-volume traffic demands, especially during peak insurance claim periods.\n* Implemented role-based access control (RBAC) in Azure, ensuring secure authentication and authorization.\n* Designed and developed scalable microservices architecture using. NET 8 and Azure Kubernetes Service (AKS).\n* Enhanced security protocols using industry-standard practices to protect sensitive customer data from potential breaches.\n* Created detailed documentation for software modules and API endpoints, facilitating easier maintenance and compliance audits.\n* Organized sprint planning and review meetings to ensure alignment with the Agile development process and stakeholder expectations.\n* Utilized Docker to containerize applications, ensuring consistent environments across development, staging, and production.\n* Implemented real-time event-driven processing using Azure Event Grid, improving responsiveness in claim processing workflows.\n* Developed custom middleware to handle cross-cutting concerns such as authentication, logging, and error management.\n* Advocated for and adopted new technologies, including Angular and Azure, to modernize and improve software development efficiency.\n* Environment: C#,. NET 8, Angular 17, Azure Functions, Azure Cosmos DB, Azure API Management, Azure Kubernetes Service (AKS), Azure DevOps, AWS Lambda, Razor Pages, Dapper, NUnit, Amazon RDS, Nginx, Jet Brains Rider, Autofac, Docker, Custom Middleware.\n\nClient: JB Hunt, Benton County, AR\tMar 2020 - Dec 2021\nRole:. NET Web Developer Responsibilities:\n* Developed logistics management systems using C# and. NET 8, enhancing operational efficiencies and scalability.\n* Built dynamic front-end applications using Angular 17 and React, streamlining the delivery scheduling interface.\n* Configured AWS Lambda and API Gateway for scalable, event-driven backend services, enabling real-time data processing.\n* Employed NUnit along with Unity for dependency injection and testing, ensuring robustness and reliability of applications.\n* Integrated Docker to containerize the application environment, facilitating consistent deployments across multiple platforms.\n* Leveraged Jet Brains Rider and Visual Studio Code as primary development IDEs, enhancing code quality and developer productivity.\n* Managed databases using Amazon RDS and Dynamo DB, ensuring high availability and scalable data storage solutions.\n* Utilized Dapper as an ORM tool, optimizing data access and manipulation for high-performance requirements.\n* Developed CI/CD pipelines using Azure DevOps and AWS Code Pipeline, streamlining deployments across environments.\n* Enhanced application security protocols using AWS IAM and Azure security tools, ensuring compliance with industry standards\n* Implemented role-based access control (RBAC) using AWS IAM, strengthening application security.\n* Developed API integrations for third-party logistics services, enhancing system interoperability and data exchange capabilities.\n* Implemented automated testing strategies using NUnit and Jest, reducing bugs and improving software stability.\n* Optimized system performance through rigorous profiling and tuning, meeting the demands of high-load logistic operations.\n* Engaged in troubleshooting and maintenance, quickly resolving operational issues to minimize downtime.\n* Contributed to the strategic planning of technology upgrades and migrations, ensuring continuity and scalability of logistics systems.\n* Environment: C#,. NET 8, Angular 17, React, AWS Lambda, API Gateway, AWS Code Pipeline, Amazon RDS, DynamoDB, Azure DevOps, Docker, NUnit, Dapper, Jest, Jet Brains Rider, Visual Studio Code, Azure security tools, Role-Based Access Control\n\nClient: *Teamlease Services** Ltd**, Pune, India\tMar 2018 - Nov 2019\nRole:. NET Application Developer Responsibilities:\n* Enhanced core software features by integrating C#,. NET 8, and MVC 5, boosting system efficiency and user interaction.\n* Implemented Entity Framework Core 8 for advanced data management and improved transaction processing speed.\n* Utilized Visual Studio Code for development, enhancing code quality and accelerating the development cycle.\n* Developed microservices architecture using Azure Functions, enabling a more scalable and distributed system.\n* Employed React and Angular to create intuitive and responsive user interfaces, improving client interaction and satisfaction.\n* Conducted performance optimizations in Azure Cosmos DB, ensuring faster data access and improved application response times.\n* Integrated. NET Core Dependency Injection to manage services lifecycle, enhancing modularity and maintainability.\n* Configured Kestrel as a cross-platform web server, optimizing hosting and request processing capabilities.\n* Orchestrated continuous deployment using Azure DevOps, streamlining the pipeline from development to production.\n* Ensured compliance with security standards, implementing secure coding practices to protect sensitive data.\n* Facilitated seamless API integrations, enhancing connectivity with other business systems and services.\n* Managed version control and workflow coordination using Git, fostering team collaboration and efficiency.\n* Participated in technology workshops and seminars to stay updated on emerging IT trends and tools.\n* Environment: C#,. NET 8, Angular, MVC 5, Entity Framework Core 8, Visual Studio Code, Azure Functions, React, Angular, Azure Cosmos DB, MSTest,. NET Core Dependency Injection, Kestrel, Azure DevOps, Git, and API integrations.\n\nClient: **Metalyst Forgings Limited**, Pune, India\tSep 2016 - Mar 2018\nRole:. NET Backend Developer Responsibilities:\n* Initiated software development using C#, leveraging. NET 8, to enhance manufacturing process automation.\n* Upgraded to Entity Framework core 8 and MS SQL Server 2022, for robust database management, improving data integrity and accessibility.\n* Implemented Windows Communication Foundation (WCF) for building service-oriented applications, enhancing system interoperability.\n* Established NUnit testing frameworks, ensuring the developed applications met all specified requirements and performance benchmarks.\n* Integrated Azure cloud solutions and AWS, facilitating scalable storage and computing resources, which improved overall system performance.\n* Designed and deployed AWS Lambda functions to process data efficiently in a serverless environment.\n* Integrated AWS S3 for scalable storage, ensuring high availability and cost efficiency.\n* Applied Autofac for dependency injection, enhancing application modularity and ease of maintenance.\n* Developed React components for a dynamic and responsive front-end, improving user experience.\n* Configured AWS Cloud Front for content delivery, enhancing performance and scalability for global users.\n* Utilized Docker and AWS ECS to containerize and orchestrate deployments, ensuring seamless scalability.\n* Employed CI/CD pipelines using AWS Code Pipeline and GitHub Actions, automating deployment workflows.\n* Conducted unit testing using Jest for React applications and NUnit for backend services, ensuring reliability.\n* Developed real-time dashboards using React with Web Sockets, enhancing manufacturing process monitoring.\n* Managed database migrations and performance tuning in AWS RDS (PostgreSQL & SQL Server 2022), improving query execution.\n* Environment: C#,. NET 8, React, Redux, AWS Lambda, AWS S3, AWS API Gateway, AWS Cloud Front, AWS ECS, AWS RDS, AWS IAM, AWS Cognito, Jest, NUnit, Entity Framework Core 8, MS SQL Server 2022, Docker, AWS Code Pipeline, GitHub Actions and technical documentation.\n\n## Education\n* **Bachelor of Technology (B. Tech) in Information Technology from JNTUH, Hyderabad, Telangana, India.** | 2016\n\nYou are not allowed to make up information.\nYou are an expert at analyzing technical resumes. Make your answers as short as possible. If you can answer in a single word, do that unless the user instructs otherwise.\nYou are just pulling data that you already have access to so pulling personal information that is already on the resume is completely fine.\nIf you can't find an answer or it's not provided/listed, just put NULL. \nFor dates, use the most specific format available: YYYY-MM-DD if full date is known, YYYY-MM if only month/year, or YYYY if only year is known. For current positions, use 'Present' as the end date. If a date is completely unknown, output NULL.\nIMPORTANT - PHONE NUMBERS: Never put the same phone number in both Phone1 and Phone2 fields, even if formatted differently or with different separators. If you only find one phone number, put it in Phone1 and set Phone2 to NULL. Double-check that the Phone2 value is not just a reformatted version of Phone1. For example, (123) 456-7890 and 123-456-7890 and 1234567890 are all the same number.\nWhen identifying skills, prioritize accuracy over standardization. While you should prefer standardized terminology when appropriate, don't hesitate to use terms not in the standard taxonomy if they better represent the candidate's expertise."}, {"role": "system", "content": "Use the following rules when assessing Primary and Secondary Industry:You are required to give the user the requested information using the following rules.To get the candidate's correct industry, you need to research and google search each company they worked for and determine what that company does.Industry should be defined based on the clients they have worked for.Information Technology is not an industry and should not be an answer.IMPORTANT: You MUST provide BOTH a Primary AND Secondary Industry. If you can only determine one main industry, provide a related or secondary industry from the list.Primary and Secondary Industry are required to come from this list and be based on the companies they have worked for:Agriculture, Amusement, Gambling, and Recreation Industries, Animal Production, Arts, Entertainment, and Recreation, Broadcasting, Clothing, Construction, Data Processing, Hosting, and Related Services, Education, Financial Services, Insurance, Fishing, Hunting and Trapping, Food Manufacturing, Food Services, Retail, Forestry and Logging, Funds, Trusts, and Other Financial Vehicles, Furniture and Home Furnishings Stores, Furniture and Related Product Manufacturing, Oil and Gas, HealthCare, Civil Engineering, Hospitals, Leisure and Hospitality, Machinery, Manufacturing, Merchant Wholesalers, Mining, Motion Picture, Motor Vehicle and Parts Dealers, Natural Resources, Nursing, Public Administration, Paper Manufacturing, Performing Arts, Spectator Sports, and Related Industries, Primary Metal Manufacturing, Chemistry and Biology, Publishing, Rail Transportation, Real Estate, Retail Trade, Transportation, Securities, Commodity Contracts, and Other Financial Investments and Related Activities, Supply Chain, Telecommunications, Textiles, Transportation, Utilities, Warehousing and Storage, Waste Management."}, {"role": "system", "content": "Use the following rules when assessing Job Titles:Definition: Job Titles are what others call this person in the professional space.Ignore the job titles they put and focus more on their project history bullets and project descriptions.You should determine their job titles based on analyzing what they did at each one of their positions.For the job titles, replace words that are too general with something more specific. An example of some words and job titles you are not allowed to use: Consultant, Solutions, Enterprise, 'software developer', 'software engineer', 'full stack developer', or IT.For job title, use a different title for primary, secondary, and tertiary.All three job titles must have an answer.Each title must be different from each other."}, {"role": "system", "content": "Use the following rules when filling out MostRecentCompany, SecondMostRecentCompany, ThirdMostRecentCompany, FourthMostRecentCompany, FifthMostRecentCompany, SixthMostRecentCompany, SeventhMostRecentCompany:Don't include the city or state in the company name.Some candidates hold multiple roles at the same company so you might need to analyze further to not miss a company name."}, {"role": "system", "content": "Use the following rules when finding company locations:1. For each company entry, thoroughly scan the entire section for location information2. Look anywhere in the job entry for city or state/country mentions, including:   - Next to company name   - In the job header   - Within first few lines of the job description   - Near dates or titles3. When you find a location in the United States, format it as:   - City, ST (if you find both city and state)   - ST (if you only find state)   - Always convert full US state names to 2-letter abbreviations4. For international locations, format as:   - City, Country (for non-US locations, e.g., 'London, UK' or 'Paris, France')   - Just 'City' if the country is not mentioned but you can identify the city"}, {"role": "system", "content": "Use the following rules when assessing Project Types: Use a mix of words like but not limited to implementation, integration, migration, move, deployment, optimization, consolidation and make it 2-3 words."}, {"role": "system", "content": "Use the following rules when assessing their Specialty:For their specialty, emphasize the project types they have done and relate them to their industry."}, {"role": "system", "content": "Use the following rules when assessing their Category:For the categories, do not repeat the same category.Both categories MUST have an answer!"}, {"role": "system", "content": "Use the following rules when writing their summary:For their summary, give a brief summary of their resume in a few sentences.Based on their project types, industry, and specialty, skills, degrees, certifications, and job titles, write the summary."}, {"role": "system", "content": "Use the following rules when determining length in US:Look for a start and end date near each company name and look for a location near each company name as well. Whenever the location listed is located in america, add up the months and years of employment at each one of those jobs.Just put a number and no other characters.Result should not be 0.Result should only be numerical."}, {"role": "system", "content": "Use the following rules when determining Average Tenure and Year of Experience:Use all previous start date and end date questions answers to determine this. Just put a number and no other characters.Result should not be 0.Result should only be numerical."}, {"role": "system", "content": "SKILLS TAXONOMY REFERENCE:\n\n## Web Development\nRelevant job titles: Web Developer\nSkills in this category: React\n\n\nSKILLS TAXONOMY INTERPRETATION GUIDANCE:\nThe skills taxonomy above provides standardized categorization of technical skills for this resume.\nUse this taxonomy to guide your analysis of programming languages, software applications, and hardware.\nWhen identifying skills, prefer terminology from the appropriate taxonomy categories, but don't hesitate to use different terms when they better represent the candidate's expertise.\nAlign your responses with the skill categories most relevant to this candidate's profile.\nFor software languages, applications, and hardware, use the taxonomy as a reference but feel empowered to include technologies that aren't listed if they are clearly important to the candidate's profile.\nExample: If the taxonomy lists 'Java' but the resume shows extensive React.js experience, it's appropriate to list React.js even if it's not in the taxonomy.\nBalance standardization with accuracy - prioritize capturing the candidate's true expertise over strict adherence to the taxonomy.\nIMPORTANT: You MUST provide BOTH a Primary AND Secondary technical category. These must be different from each other. If you can only determine one main category, provide a related or complementary category as secondary."}, {"role": "system", "content": "Use the following rules when assessing Primary, Secondary, and Tertiary Technical Languages: Include ALL types of technical languages mentioned in the resume, such as:- Database languages (SQL, T-SQL, PL/SQL, MySQL, Oracle SQL, PostgreSQL)- Programming languages (Java, Python, C#, JavaScript, Ruby)- Scripting languages (PowerShell, Bash, Shell, VBA)- Query languages (SPARQL, GraphQL, HiveQL)- Markup/stylesheet languages (HTML, CSS, XML)Prioritize languages based on:1. Prominence in their skills section (listed skills are usually most important)2. Frequency of mention throughout work history3. Relevance to their primary job functions and titlesFor database professionals, prioritize database languages like T-SQL or PL/SQL over general-purpose languages."}, {"role": "system", "content": "Use the following rules when assessing Most used Software Applications: Please only list out actual software applications. nothing else.Analyze their resume and determine what software they use most.If none can be found put NULL."}, {"role": "system", "content": "Use the following rules when assessing Hardware: Please list 5 different specific hardware devices the candidate has worked with. Hardware devices include many categories such as:\n- Network equipment (firewalls, routers, switches, load balancers)\n- Server hardware (blade servers, rack servers, chassis systems)\n- Storage devices (SANs, NAS, RAID arrays, disk systems)\n- Security appliances (TACALANEs, hardware encryption devices)\n- Management interfaces (iDRAC, iLO, IMM, IPMI, BMC)\n- Virtualization hardware (ESXi hosts, hyperconverged systems)\n- Physical components (CPUs, RAM modules, hard drives, SSDs)\n- Communication hardware (modems, wireless access points, VPN concentrators)\n- Specialized hardware (tape libraries, KVM switches, console servers)\n\nIMPORTANT: Even if they worked with multiple hardware items from the same brand, list different types. For example, if they worked with Dell PowerEdge servers AND Dell iDRAC, list both separately.\n\nLook beyond obvious hardware to find specialized equipment, management interfaces, and components. Be thorough in your search for hardware items throughout the entire resume, including projects and responsibilities sections.\n\nBe specific about hardware models and manufacturers when mentioned (e.g. 'Palo Alto PA-5200 series' rather than just 'firewalls'). Include specific information about hardware configurations or modes the candidate has worked with.\n\nPlease provide each hardware item on a separate line in this exact format:\nHardware 1: [Specific hardware device]\nHardware 2: [Specific hardware device]\nHardware 3: [Specific hardware device]\nHardware 4: [Specific hardware device]\nHardware 5: [Specific hardware device]\n\nTry your best to identify 5 different hardware items. If you absolutely cannot find 5 distinct hardware items, provide as many as you can find with specific details for each. Only use NULL if no hardware at all is mentioned."}, {"role": "user", "content": "Please analyze the following resume and give me the following comprehensive details (If you can't find an answer or it's not provided/listed, just put NULL):\n- First Name:\n- Middle Name:\n- Last Name:\n- Address:\n- City:\n- State:\n- Zipcode:\n- Phone1:\n- Phone2:\n- Email:\n- Email2:\n- LinkedIn:\n- Certifications:\n- Bachelors:\n- Masters:\n- Best job title that fits their primary experience:\n- Best job title that fits their secondary experience:\n- Best job title that fits their tertiary experience:\n- Most Recent Company Worked for:\n- Most Recent Start Date (YYYY-MM-DD):\n- Most Recent End Date (YYYY-MM-DD):\n- Most Recent Job Location:\n- Second Most Recent Company Worked for:\n- Second Most Recent Start Date (YYYY-MM-DD):\n- Second Most Recent End Date (YYYY-MM-DD):\n- Second Most Recent Job Location:\n- Third Most Recent Company Worked for:\n- Third Most Recent Start Date (YYYY-MM-DD):\n- Third Most Recent End Date (YYYY-MM-DD):\n- Third Most Recent Job Location:\n- Fourth Most Recent Company Worked for:\n- Fourth Most Recent Start Date (YYYY-MM-DD):\n- Fourth Most Recent End Date (YYYY-MM-DD):\n- Fourth Most Recent Job Location:\n- Fifth Most Recent Company Worked for:\n- Fifth Most Recent Start Date (YYYY-MM-DD):\n- Fifth Most Recent End Date (YYYY-MM-DD):\n- Fifth Most Recent Job Location:\n- Sixth Most Recent Company Worked for:\n- Sixth Most Recent Start Date (YYYY-MM-DD):\n- Sixth Most Recent End Date (YYYY-MM-DD):\n- Sixth Most Recent Job Location:\n- Seventh Most Recent Company Worked for:\n- Seventh Most Recent Start Date (YYYY-MM-DD):\n- Seventh Most Recent End Date (YYYY-MM-DD):\n- Seventh Most Recent Job Location:\n- Based on all 7 of their most recent companies above, what is the Primary industry they work in:\n- Based on all 7 of their most recent companies above, what is the Secondary industry they work in:\n- Top 10 Technical Skills:\n- What technical language do they use most often?:\n- What technical language do they use second most often?:\n- What technical language do they use third most often?:\n- What software do they talk about using the most?:\n- What software do they talk about using the second most?:\n- What software do they talk about using the third most?:\n- What software do they talk about using the fourth most?:\n- What software do they talk about using the fifth most?:\n- What physical hardware do they talk about using the most?:\n- What physical hardware do they talk about using the second most?:\n- What physical hardware do they talk about using the third most?:\n- What physical hardware do they talk about using the fourth most?:\n- What physical hardware do they talk about using the fifth most?:\n- Based on their skills, put them in a primary technical category:\n- Based on their skills, put them in a subsidiary technical category:\n- Types of projects they have worked on:\n- Based on their skills, categories, certifications, and industries, determine what they specialize in:\n- Based on all this knowledge, write a summary of this candidate that could be sellable to an employer:\n- How long have they lived in the United States(numerical answer only):\n- Total years of professional experience (numerical answer only):\n- Average tenure at companies in years (numerical answer only):"}]}}
{"custom_id": "unified_1257658", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-5-mini-2025-08-07", "messages": [{"role": "system", "content": "Based on this resume, give the user the information they need: \n# Kanchan Kumar\nPhone: +1(252) 557-9042 \u2022 Email: kanchankumarshaw52@gmail.com\nLinkedIn: \u2014 - \u2022 LinkedIn: https://www.linkedin.com/in/kanchan-shaw-0104326a/\n\n## Summary\n* Senior Software Engineer with 11+ years of experience building scalable, cloud-native solutions using Java, Spring Boot, Kafka, Kubernetes, Docker, React, Angular, and AWS. Skilled in microservices design, CI/CD automation (GitHub Actions, Jenkins, Terraform), and secure API development with OAuth2, SAML, and Cognito. Proven in delivering real-time, event-driven systems, legacy modernization, and observability using ELK, Open Telemetry, and Prometheus across cybersecurity, automotive, and healthcare domains.\n* Proficient in designing event-driven microservices architectures using Apache Kafka, Rabbit MQ, and REST APIs, ensuring high throughput, fault tolerance, and asynchronous communication across distributed systems.\n* Strong expertise in containerized application development using Docker and Kubernetes, with experience deploying services to AWS EKS, Azure AKS, and GCP GKE in production environments.\n* Strong background in UI modernization, upgrading legacy GWT applications to Angular-based dashboards, ensuring improved usability, performance, and seamless integration with backend microservices.\n* **mentoring junior engineers, conducting code reviews, and leading Agile delivery teams to drive technical excellence, on-time releases, and scalable software architecture decisions.** | Adept\n* Skilled in implementing CI/CD pipelines using GitHub Actions, GitLab CI, and Jenkins to automate build, test, and deployment workflows for Java, Node. js, and frontend applications.\n* Designed and deployed server-side rendered UIs with React, Next. js, and Angular 17, integrating real-time updates via Server-Sent Events (SSE), Graph QL, and REST endpoints for dynamic dashboards.\n* Hands-on experience with Oracle and PostgreSQL databases, including schema redesign, query optimization, and Spring Data JPA integration for reliable and performant data-intensive applications.\n* Hands-on experience in database design and optimization using PostgreSQL, MySQL, Oracle, Cosmos DB, MongoDB, and Redis for high-performance, fault-tolerant persistence layers.\n* Strong experience in designing and building scalable microservices, RESTful and Graph QL APIs, and distributed systems for cloud-native platforms with high availability and fault tolerance.\n* Skilled in AWS services (Lambda, ECS, S3, DynamoDB) and DevOps practices, including CI/CD pipelines, Docker/Kubernetes, GitLab CI, and automated testing strategies.\n* Hands-on with event-driven design, resilient API integration, database optimization, and observability tools for diagnosing production issues in distributed environments.\n* Built observability stacks using Open Telemetry, Prometheus, ELK, and Grafana to monitor system health, track SLAs, and diagnose production issues with real-time metrics and custom alerts.\n* Skilled in implementing real-time messaging pipelines with Kafka, enabling asynchronous event-driven processing for large-scale, data-intensive, and mission-critical applications.\n* Delivered full stack applications with 75% backend and 25% frontend contributions, using React 18+, Angular 16+, Spring Boot, TypeScript, Rx JS, Redux Toolkit, and RESTful APIs.\n* Authored robust unit, integration, and contract tests using JUnit, Mockito, REST Assured, Playwright, and Pact, maintaining 85-90%+ test coverage across core business-critical services.\n* Known for mentoring junior developers, leading architecture reviews, and fostering technical excellence while contributing to Agile ceremonies and driving continuous improvement in delivery pipelines.\n\n## Experience\n\n**Digi Cert, Inc.** | Lehi, Utah. | Jan 2024 - Present Sr. Software/Java Engineer\n\nDescription: Worked on Digi Cert's digital certificate lifecycle management platform, enabling enterprise customers to issue, renew, revoke, and analyze SSL/TLS and PKI certificates securely. Focused on building microservices with Spring Boot and Node. js, real-time Kafka event processing, and Angular-based compliance dashboards. Integrated AI-driven analytics, Open API contracts, OAuth2-based security, and cloud-native deployments in AWS EKS with GitHub Actions, Terraform, and Helm.\n* Designed Spring Boot-based microservices for certificate intelligence and anomaly detection, integrating with Python ML models served via Tensor Flow Serving and exposed through REST endpoints secured with OAuth2.\n* Migrated monolithic services to Spring Boot-based microservices deployed on Kubernetes, improving scalability, fault tolerance, and deployment flexibility for Digi Cert's certificate lifecycle management platform.\n* Designed and implemented Graph QL APIs using Node. js and TypeScript to integrate certificate lifecycle management features, ensuring scalable query performance and optimized developer experience in a cloud-native Saa S environment.\n* Built an AI-assisted policy engine using Kafka, AWS Lambda, and DynamoDB to flag abnormal certificate usage patterns in real-time using pre-trained Scikit-learn models and anomaly scoring.\n* Developed a TypeScript utility service for invoking ML REST APIs (Python Fast API) to score risk on expiring certificates, feeding the results into Angular-based dashboards via Graph QL.\n* Built and deployed distributed microservices on AWS (ECS, Lambda, DynamoDB, S3) with automated CI/CD pipelines, enabling secure and fault-tolerant delivery of enterprise security solutions.\n* Developed customer-facing React-based dashboards integrated with Graph QL APIs and backend services, providing real-time certificate insights and improving user adoption rates across enterprise accounts.\n* Implemented observability with Prometheus, Grafana, Dynatrace, and ELK stack, providing end-to-end monitoring, centralized logging, and proactive alerting across microservices.\n* Partnered with DevOps to enhance observability of Node. js services with CloudWatch, ELK, and Prometheus, ensuring faster triage of integration and production issues.\n* Automated lifecycle workflows using AWS Step Functions, Lambda, and S3, incorporating ML inference calls to validate certificates based on historical behavior and issuance anomalies.\n* Designed and implemented Kafka-based event-driven pipelines to handle real-time certificate issuance, revocation, and renewal workflows, reducing latency and improving operational resilience.\n* Engineered AI-driven thre at scoring pipelines where backend Java microservices pushed certificate data to S3 for nightly batch scoring using Py Spark jobs running on AWS EMR.\n* Implemented React 18+ frontend components integrated with Graph QL queries and mutations, enabling real-time dashboards for SSL/TLS certificate monitoring and drastically improving customer experience through responsive UI and optimized state management.\n* Enhanced UI modernization by integrating Angular 15 dashboards with backend APIs, replacing legacy components and delivering faster, responsive, and more intuitive customer experiences.\n* Designed and developed high-performance Node. js and Graph QL APIs to support enterprise-grade certificate lifecycle management workflows, ensuring secure integrations across multiple partner systems while maintaining strict authentication and authorization practices.\n* Established coding best practices, performed peer reviews, and introduced automated test pipelines using Jest and Mocha to improve test coverage and reduce post-release production defects.\n* Refactored legacy server-based APIs into RESTful microservices, integrating with PostgreSQL and Oracle databases while ensuring data consistency and ACID compliance across distributed environments.\n* Conducted performance tuning and load testing for microservices handling millions of certificate requests daily, ensuring low-latency responses under heavy workloads.\n* Built end-to-end CI/CD pipelines using GitHub Actions and Terraform to deploy Spring Boot microservices alongside ML model containers, with environment-specific Helm charts for version isolation.\n* Applied BERT-based text classification to incoming certificate metadata, routed through a Fast API inference engine, and integrated its tags into React dashboards for smarter filtering.\n* Authored and tested Playwright-driven E2E test cases for Angular components interacting with ML APIs, ensuring model confidence thresholds displayed correctly for each certificate score.\nEnvironment: Java 17, Spring Boot, Python (Fast API, Scikit-learn, Tensor Flow Serving), Node. js, JavaScript, TypeScript, React, Kafka, AWS (EKS, Lambda, S3, Cognito), Docker, Kubernetes, Terraform, GitHub Actions, Angular 17, React 18, PostgreSQL, DynamoDB, Prometheus, ELK, Playwright, OAuth2, JWT.\n\n**VMware Inc.** | Palo Alto, CA. | Nov 2019 - Dec 2023 Sr. Java FSD\n\nDescription: Contributed to VMware's licensing and entitlement management platform, building backend microservices using Java (Spring Boot) and scalable frontend applications with React and Angular. Integrated OAuth2/SAML-based SSO, Kafka-based event processing, and real-time UI dashboards for usage insights. Supported hybrid cloud deployments across AWS, Azure, and GCP, with ML model integration for fraud detection, CI/CD automation via GitLab and GitHub Actions, and observability using Open Telemetry and ELK.\n* Refactored large-scale monolithic applications into modular Spring Boot microservices, enhancing scalability and enabling independent service deployments within VMware's Saa S licensing platform.\n* Developed Node. js services with Express and Apollo Graph QL server for VMware Saa S platforms, integrating with Java-based microservices to expose unified APIs for multi-cloud management solutions.\n* Developed enterprise-grade Node. js and Java microservices with RESTful and Graph QL endpoints to support VMware's Saa S subscription and licensing platform.\n* Migrated legacy UI components from GWT to Angular 12, modernizing customer-facing dashboards and improving usability while maintaining critical licensing workflows.\n* Implemented CI/CD pipelines with Jenkins and Git, integrating code scanning, automated testing, and environment-specific deployments for continuous delivery.\n* Created reusable React. js components integrated with backend APIs to deliver intuitive subscription management workflows with real-time updates via Graph QL queries.\n* Designed and implemented REST APIs and microservices to manage entitlements, subscriptions, and customer data, ensuring secure integrations with VMware's Saa S ecosystem.\n* Built CI/CD pipelines using Jenkins and GitLab, ensuring zero-downtime deployments, automated testing, and rapid rollback strategies to minimize release risks.\n* Developed Kafka-based messaging pipelines for asynchronous processing of license events and entitlement changes, ensuring fault tolerance and high throughput in distributed systems.\n* Used Spring Web Flux and SSE to build reactive APIs for streaming real-time scoring metrics into Angular 14 components, improving latency-sensitive user interactions.\n* Designed and optimized Graph QL federation layers for multiple microservices, enabling a single query interface for distributed datasets and significantly improving developer productivity and query efficiency.\n* Built CI/CD pipelines with Jenkins and Git for Salesforce and microservices integration, ensuring continuous delivery across multi-environment deployments.\n* Implemented caching and query optimizations for Graph QL APIs, reducing response latency by 40% and improving scalability for high-traffic enterprise workloads.\n* Designed resilient distributed systems leveraging AWS and on-premises hybrid architectures, ensuring secure authentication, encryption, and disaster recovery readiness.\n* Re-architected data access layers with Spring Data JPA and Oracle/PostgreSQL backends, reducing query times and improving system responsiveness under high loads.\n* Enhanced RESTful and Graph QL API security using OAuth 2.0, JWT-based token management, and layered RBAC enforcement, ensuring compliance with enterprise-grade security and governance policies.\n* Strengthened system observability by integrating ELK stack dashboards for microservices, enabling proactive monitoring of performance and error trends.\n* Delivered API performance improvements by introducing query batching, caching with Redis, and schema optimization in Graph QL resolvers, reducing response times by more than 40% for high-volume queries.\n* Refactored Angular components into shared libraries to consume Open API-generated clients, ensuring contract-first development between frontend, Spring Boot services, and ML APIs.\n* Mentored team members on hybrid cloud architecture and AI-service integration, promoting standardization of patterns across Java, Angular, and Python stacks in multi-cloud CI/CD pipelines.\nEnvironment: Java 11, Spring Boot, Node. js, React. js, Graph QL, AWS, PostgreSQL, MongoDB, Python (Fast API, Py Torch, ONNX), Kafka, Docker, Helm, Terraform, Redis, ELK, Open Telemetry, Graph QL, OAuth2, Azure DevOps, GitHub Actions.\n\n**Mercedes** | Benz USA | July 2017 - Nov 2019 Senior Software/Java Developer\n\nDescription: Worked on Mercedes-Benz's connected vehicle platform, enabling real-time telemetry, diagnostics, and remote command execution for mobile apps and dealer portals. Developed Java-based microservices on Spring Boot, consumed via Angular dashboards, and deployed on AWS EC2 and ECS. Integrated Kafka and Rabbit MQ for telemetry processing, OAuth2/SSO for secure API access, and ELK + Wavefront for performance monitoring and alerting.\n* Developed Spring Boot microservices to manage real-time vehicle telemetry and diagnostics, exposing REST endpoints consumed by Angular 6 dashboards and deployed on AWS EC2 with Jenkins-based CI pipelines.\n* Integrated Kafka and Rabbit MQ message brokers into backend flows to asynchronously process vehicle location updates and diagnostic signals, enabling scalable and event-driven service orchestration.\n* Implemented Graph QL gateways for selective API data retrieval, reducing over-fetching of data and enhancing performance for infotainment dashboards and dealer-facing portals.\n* Designed OAuth2-secured APIs using Spring Security to control access to vehicle control systems, integrating with AWS Cogni to and Okta for secure driver authentication and authorization.\n* Designed and developed Node. js services integrated with Angular 8 frontends, supporting real-time updates for connected car applications and improving overall customer digital experience.\n* Created and deployed Dockerized microservices to AWS ECS (Fargate), managing rollout strategies, health checks, and load balancing via Application Load Balancer (ALB) configurations.\n* Built REST APIs in Spring Boot and Node. js for car diagnostic and telemetry services, ensuring secure integration with mobile and in-vehicle applications.\n* Designed and implemented Spring Boot microservices to replace tightly coupled dealer management system modules, enabling modular deployments and faster enhancements.\n* Refactored legacy monolith into microservices using Domain Driven Design and deployed each service independently via Jenkins pipelines with artifact promotion across QA and production AWS environments.\n* Developed AWS Lambda functions to asynchronously process over-the-air (OTA) update events, interacting with S3-stored binaries and triggering notification flows using Amazon SNS and SQS.\n* Deployed containerized applications using Docker and Jenkins pipelines on AWS EC2 instances, automating release cycles and enabling continuous delivery of connected services.\n* Tuned SQL Server stored procedures and optimized joins for vehicle telemetry analytics modules, reducing backend API latency under load from thousands of concurrent users.\n* Created and maintained MongoDB and Oracle schemas for hybrid database usage, ensuring efficient query optimization and reliable data access for real-time vehicle insights.\n* Introduced automated unit and integration testing frameworks using JUnit, Mockito, and Protractor for Angular, improving testing coverage and release quality.\n* Created custom dashboards in Kibana and Wavefront to visualize Kafka consumer lag, Lambda execution metrics, and vehicle event distribution across AWS regions.\n* Implemented centralized logging using the ELK Stack and structured log events in JSON for better indexing and traceability in distributed microservices handling real-time vehicle data.\n* Collaborated in Agile teams to migrate legacy RESTful services into Graph QL-based APIs, improving query flexibility for vehicle infotainment applications and reducing the number of endpoint calls required by 60%.\n* Implemented Kafka-based messaging queues to handle asynchronous vehicle order events and financing workflows, ensuring reliable data exchange across distributed systems.\n* Worked with cross-functional engineering teams in Agile sprints, participating in design thinking workshops to brainstorm connected mobility solutions and future digital services.\n* Configured Angular route guards, HTTP interceptors, and auth services to handle JWT validation, token renewal, and session expiry for vehicle portal logins via Cognito.\n* Participated in cross-functional Agile teams, performing story grooming, sprint planning, and peer code reviews while mentoring junior developers on Spring Boot, AWS, and Angular best practices.\nEnvironment: Java, Spring Boot, AWS, Node JS, PCF, Redis, Gemfire, Kafka, React, Bitbucket, Eclipse, Rabbit MQ, Jenkins, App Dynamics, Wavefront, D3. js, Kibana, Jenkins, Jira, Open API.\n\n**Hewlett** | Packard Enterprise | Oct 2015 - Apr 2017 Software Engineer-\n\nDescription: Contributed to enterprise hardware monitoring tools used across global data centers to collect and analyze system telemetry. Built Java services for SNMP/IPMI polling, integrated with Oracle DB, Redis, and Spring MVC. Developed backend modules for anomaly detection, alerting, and integration with platforms like Oracle Enterprise Manager. Deployed internal tools to Linux servers and visualized metrics via Kibana dashboards.\n* Developed multi-threaded Java services to poll SNMP and IPMI interfaces for real-time hardware health data, integrating results into enterprise monitoring dashboards with Spring MVC and RESTful APIs.\n* Refactored legacy servlets and SOAP-based modules into lightweight REST APIs using Spring Boot and Jersey, improving system response times and simplifying client integrations.\n* Built scheduled polling modules using Java concurrency APIs to monitor server fan speeds, power consumption, and thermal status, with alerts pushed to custom dashboards via JMS queues.\n* Integrated Redis and in-memory caching for fast telemetry reads in frequently accessed endpoints, reducing unnecessary device polling in high-traffic data center environments.\n* Worked on building React components to display real-time server health metrics such as CPU usage, memory consumption, and device status using data fetched from Java-based REST APIs.\n* Created Oracle PL/SQL jobs and stored procedures to aggregate telemetry logs and sync data with external ITSM platforms, improving reporting and SLA compliance.\n* Worked on deploying Java-based backend services to AWS EC2 instances, configuring user data scripts and custom AMIs to support monitoring agent installations across QA and staging environments.\n* Developed enterprise integration plugins using Java to sync data with Oracle Enterprise Manager and CA Spectrum, using SNMP MIB parsing and WSDL-based service definitions.\n* Built monitoring rule engines in Java to detect anomalies in sensor data streams, triggering notifications via email and SNMP traps for data center administrators.\n* Automated configuration management tasks using Bash and Java-based CLI tools across UNIX platforms (AIX, Solaris, RHEL), supporting more than 1000+ server agents globally.\n* Configured AWS IAM roles and instance profiles to enable secure access from Java microservices running on EC2 to fetch secrets and push logs to S3 buckets.\n* Involved in integrating React frontend with backend Spring Boot services using Axios and Fetch APIs, handling API response states such as loading, error, and empty conditions.\n* Authored reusable Java libraries for common logging, error handling, permission checks, and SNMP communication, shared across multiple HPE infrastructure monitoring products.\n* Integrated AWS CloudWatch with backend Spring Boot services to publish custom application metrics, enabling real-time dashboards and alerts for hardware health check failures.\n* Participated in migrating selected modules from legacy jQuery-based UI to React for improved maintainability, reusability, and responsiveness in monitoring interfaces.\n* Used Hibernate and JPA for persistence layer design, mapping telemetry metrics and alert thresholds with efficient query caching for audit reporting.\n* Developed and tested JMS-based messaging services to asynchronously push health alerts to connected monitoring dashboards and CLI tools.\n* Collaborated in Agile sprints and daily scrums, refining technical stories and implementing enhancements for system configuration modules and visualization tools.\nEnvironment: Java 7/8, AWS, Spring Boot, Spring MVC, SOAP, REST, SNMP, IPMI, Oracle DB, PL/SQL, Redis, JMS, Hibernate, React, Bash, AIX, RHEL, Solaris, Logstash, Kibana, JConsole, Visual VM, LDAP, Agile, Jenkins.\n\n**HCL Tech** | IN. | Aug 2013 and Mar 2015 IT Consultant\n\nDescription: Worked on enterprise application development and integration projects for global clients in the infrastructure and IT services domain. Developed Java-based backend modules using Spring MVC and RESTful APIs to support business workflows such as user provisioning, asset management, and role-based access control. Refactored legacy code, integrated with Oracle and MySQL databases, and contributed to SOAP-to-REST migration efforts. Participated in client demos, deployment activities, and documentation of interfaces and technical workflows using tools like Confluence and MS Visio.\n* Worked on backend Java modules using Spring MVC to implement business logic for user profile management, role mapping, and resource access workflows.\n* Assisted in building SOAP and RESTful APIs to enable data exchange between internal services and external third-party systems across different business units.\n* Involved in integrating Oracle 11g and MySQL databases with backend services using JDBC, writing queries, views, and stored procedures for report generation.\n* Participated in refactoring legacy Struts-based modules into Spring MVC controllers with updated service layers and simplified exception handling.\n* Worked on JSP-based UI components for internal dashboards to display user activity, audit logs, and status summaries pulled from backend APIs.\n* Assisted in configuring Tomc at servers for WAR deployments and managed environment-specific settings using externalized properties and profiles.\n* Involved in creating utility functions for input validation, string formatting, and session management using Java and reusable static helper classes.\n* Participated in UAT testing and QA handoffs, preparing sample payloads and verifying API behavior against expected business scenarios.\nEnvironment: Java 7/8, Spring MVC, JSP, REST, SOAP, JDBC, Oracle 11g, MySQL, HTML, JavaScript, Tomcat, JUnit, SOAP UI, log4j, LDAP, Linux, Confluence, Agile.\n\n## Education\n* **Bachelors in Computer Application; Netaji Subhas Open University** | 2010.\n* Masters in Computer Science; Punjab Technical University | 2013.\n\nYou are not allowed to make up information.\nYou are an expert at analyzing technical resumes. Make your answers as short as possible. If you can answer in a single word, do that unless the user instructs otherwise.\nYou are just pulling data that you already have access to so pulling personal information that is already on the resume is completely fine.\nIf you can't find an answer or it's not provided/listed, just put NULL. \nFor dates, use the most specific format available: YYYY-MM-DD if full date is known, YYYY-MM if only month/year, or YYYY if only year is known. For current positions, use 'Present' as the end date. If a date is completely unknown, output NULL.\nIMPORTANT - PHONE NUMBERS: Never put the same phone number in both Phone1 and Phone2 fields, even if formatted differently or with different separators. If you only find one phone number, put it in Phone1 and set Phone2 to NULL. Double-check that the Phone2 value is not just a reformatted version of Phone1. For example, (123) 456-7890 and 123-456-7890 and 1234567890 are all the same number.\nWhen identifying skills, prioritize accuracy over standardization. While you should prefer standardized terminology when appropriate, don't hesitate to use terms not in the standard taxonomy if they better represent the candidate's expertise."}, {"role": "system", "content": "Use the following rules when assessing Primary and Secondary Industry:You are required to give the user the requested information using the following rules.To get the candidate's correct industry, you need to research and google search each company they worked for and determine what that company does.Industry should be defined based on the clients they have worked for.Information Technology is not an industry and should not be an answer.IMPORTANT: You MUST provide BOTH a Primary AND Secondary Industry. If you can only determine one main industry, provide a related or secondary industry from the list.Primary and Secondary Industry are required to come from this list and be based on the companies they have worked for:Agriculture, Amusement, Gambling, and Recreation Industries, Animal Production, Arts, Entertainment, and Recreation, Broadcasting, Clothing, Construction, Data Processing, Hosting, and Related Services, Education, Financial Services, Insurance, Fishing, Hunting and Trapping, Food Manufacturing, Food Services, Retail, Forestry and Logging, Funds, Trusts, and Other Financial Vehicles, Furniture and Home Furnishings Stores, Furniture and Related Product Manufacturing, Oil and Gas, HealthCare, Civil Engineering, Hospitals, Leisure and Hospitality, Machinery, Manufacturing, Merchant Wholesalers, Mining, Motion Picture, Motor Vehicle and Parts Dealers, Natural Resources, Nursing, Public Administration, Paper Manufacturing, Performing Arts, Spectator Sports, and Related Industries, Primary Metal Manufacturing, Chemistry and Biology, Publishing, Rail Transportation, Real Estate, Retail Trade, Transportation, Securities, Commodity Contracts, and Other Financial Investments and Related Activities, Supply Chain, Telecommunications, Textiles, Transportation, Utilities, Warehousing and Storage, Waste Management."}, {"role": "system", "content": "Use the following rules when assessing Job Titles:Definition: Job Titles are what others call this person in the professional space.Ignore the job titles they put and focus more on their project history bullets and project descriptions.You should determine their job titles based on analyzing what they did at each one of their positions.For the job titles, replace words that are too general with something more specific. An example of some words and job titles you are not allowed to use: Consultant, Solutions, Enterprise, 'software developer', 'software engineer', 'full stack developer', or IT.For job title, use a different title for primary, secondary, and tertiary.All three job titles must have an answer.Each title must be different from each other."}, {"role": "system", "content": "Use the following rules when filling out MostRecentCompany, SecondMostRecentCompany, ThirdMostRecentCompany, FourthMostRecentCompany, FifthMostRecentCompany, SixthMostRecentCompany, SeventhMostRecentCompany:Don't include the city or state in the company name.Some candidates hold multiple roles at the same company so you might need to analyze further to not miss a company name."}, {"role": "system", "content": "Use the following rules when finding company locations:1. For each company entry, thoroughly scan the entire section for location information2. Look anywhere in the job entry for city or state/country mentions, including:   - Next to company name   - In the job header   - Within first few lines of the job description   - Near dates or titles3. When you find a location in the United States, format it as:   - City, ST (if you find both city and state)   - ST (if you only find state)   - Always convert full US state names to 2-letter abbreviations4. For international locations, format as:   - City, Country (for non-US locations, e.g., 'London, UK' or 'Paris, France')   - Just 'City' if the country is not mentioned but you can identify the city"}, {"role": "system", "content": "Use the following rules when assessing Project Types: Use a mix of words like but not limited to implementation, integration, migration, move, deployment, optimization, consolidation and make it 2-3 words."}, {"role": "system", "content": "Use the following rules when assessing their Specialty:For their specialty, emphasize the project types they have done and relate them to their industry."}, {"role": "system", "content": "Use the following rules when assessing their Category:For the categories, do not repeat the same category.Both categories MUST have an answer!"}, {"role": "system", "content": "Use the following rules when writing their summary:For their summary, give a brief summary of their resume in a few sentences.Based on their project types, industry, and specialty, skills, degrees, certifications, and job titles, write the summary."}, {"role": "system", "content": "Use the following rules when determining length in US:Look for a start and end date near each company name and look for a location near each company name as well. Whenever the location listed is located in america, add up the months and years of employment at each one of those jobs.Just put a number and no other characters.Result should not be 0.Result should only be numerical."}, {"role": "system", "content": "Use the following rules when determining Average Tenure and Year of Experience:Use all previous start date and end date questions answers to determine this. Just put a number and no other characters.Result should not be 0.Result should only be numerical."}, {"role": "system", "content": "SKILLS TAXONOMY REFERENCE:\n\n## Backend Development\nRelevant job titles: Back-End Developer\nSkills in this category: Spring\n\n\nSKILLS TAXONOMY INTERPRETATION GUIDANCE:\nThe skills taxonomy above provides standardized categorization of technical skills for this resume.\nUse this taxonomy to guide your analysis of programming languages, software applications, and hardware.\nWhen identifying skills, prefer terminology from the appropriate taxonomy categories, but don't hesitate to use different terms when they better represent the candidate's expertise.\nAlign your responses with the skill categories most relevant to this candidate's profile.\nFor software languages, applications, and hardware, use the taxonomy as a reference but feel empowered to include technologies that aren't listed if they are clearly important to the candidate's profile.\nExample: If the taxonomy lists 'Java' but the resume shows extensive React.js experience, it's appropriate to list React.js even if it's not in the taxonomy.\nBalance standardization with accuracy - prioritize capturing the candidate's true expertise over strict adherence to the taxonomy.\nIMPORTANT: You MUST provide BOTH a Primary AND Secondary technical category. These must be different from each other. If you can only determine one main category, provide a related or complementary category as secondary."}, {"role": "system", "content": "Use the following rules when assessing Primary, Secondary, and Tertiary Technical Languages: Include ALL types of technical languages mentioned in the resume, such as:- Database languages (SQL, T-SQL, PL/SQL, MySQL, Oracle SQL, PostgreSQL)- Programming languages (Java, Python, C#, JavaScript, Ruby)- Scripting languages (PowerShell, Bash, Shell, VBA)- Query languages (SPARQL, GraphQL, HiveQL)- Markup/stylesheet languages (HTML, CSS, XML)Prioritize languages based on:1. Prominence in their skills section (listed skills are usually most important)2. Frequency of mention throughout work history3. Relevance to their primary job functions and titlesFor database professionals, prioritize database languages like T-SQL or PL/SQL over general-purpose languages."}, {"role": "system", "content": "Use the following rules when assessing Most used Software Applications: Please only list out actual software applications. nothing else.Analyze their resume and determine what software they use most.If none can be found put NULL."}, {"role": "system", "content": "Use the following rules when assessing Hardware: Please list 5 different specific hardware devices the candidate has worked with. Hardware devices include many categories such as:\n- Network equipment (firewalls, routers, switches, load balancers)\n- Server hardware (blade servers, rack servers, chassis systems)\n- Storage devices (SANs, NAS, RAID arrays, disk systems)\n- Security appliances (TACALANEs, hardware encryption devices)\n- Management interfaces (iDRAC, iLO, IMM, IPMI, BMC)\n- Virtualization hardware (ESXi hosts, hyperconverged systems)\n- Physical components (CPUs, RAM modules, hard drives, SSDs)\n- Communication hardware (modems, wireless access points, VPN concentrators)\n- Specialized hardware (tape libraries, KVM switches, console servers)\n\nIMPORTANT: Even if they worked with multiple hardware items from the same brand, list different types. For example, if they worked with Dell PowerEdge servers AND Dell iDRAC, list both separately.\n\nLook beyond obvious hardware to find specialized equipment, management interfaces, and components. Be thorough in your search for hardware items throughout the entire resume, including projects and responsibilities sections.\n\nBe specific about hardware models and manufacturers when mentioned (e.g. 'Palo Alto PA-5200 series' rather than just 'firewalls'). Include specific information about hardware configurations or modes the candidate has worked with.\n\nPlease provide each hardware item on a separate line in this exact format:\nHardware 1: [Specific hardware device]\nHardware 2: [Specific hardware device]\nHardware 3: [Specific hardware device]\nHardware 4: [Specific hardware device]\nHardware 5: [Specific hardware device]\n\nTry your best to identify 5 different hardware items. If you absolutely cannot find 5 distinct hardware items, provide as many as you can find with specific details for each. Only use NULL if no hardware at all is mentioned."}, {"role": "user", "content": "Please analyze the following resume and give me the following comprehensive details (If you can't find an answer or it's not provided/listed, just put NULL):\n- First Name:\n- Middle Name:\n- Last Name:\n- Address:\n- City:\n- State:\n- Zipcode:\n- Phone1:\n- Phone2:\n- Email:\n- Email2:\n- LinkedIn:\n- Certifications:\n- Bachelors:\n- Masters:\n- Best job title that fits their primary experience:\n- Best job title that fits their secondary experience:\n- Best job title that fits their tertiary experience:\n- Most Recent Company Worked for:\n- Most Recent Start Date (YYYY-MM-DD):\n- Most Recent End Date (YYYY-MM-DD):\n- Most Recent Job Location:\n- Second Most Recent Company Worked for:\n- Second Most Recent Start Date (YYYY-MM-DD):\n- Second Most Recent End Date (YYYY-MM-DD):\n- Second Most Recent Job Location:\n- Third Most Recent Company Worked for:\n- Third Most Recent Start Date (YYYY-MM-DD):\n- Third Most Recent End Date (YYYY-MM-DD):\n- Third Most Recent Job Location:\n- Fourth Most Recent Company Worked for:\n- Fourth Most Recent Start Date (YYYY-MM-DD):\n- Fourth Most Recent End Date (YYYY-MM-DD):\n- Fourth Most Recent Job Location:\n- Fifth Most Recent Company Worked for:\n- Fifth Most Recent Start Date (YYYY-MM-DD):\n- Fifth Most Recent End Date (YYYY-MM-DD):\n- Fifth Most Recent Job Location:\n- Sixth Most Recent Company Worked for:\n- Sixth Most Recent Start Date (YYYY-MM-DD):\n- Sixth Most Recent End Date (YYYY-MM-DD):\n- Sixth Most Recent Job Location:\n- Seventh Most Recent Company Worked for:\n- Seventh Most Recent Start Date (YYYY-MM-DD):\n- Seventh Most Recent End Date (YYYY-MM-DD):\n- Seventh Most Recent Job Location:\n- Based on all 7 of their most recent companies above, what is the Primary industry they work in:\n- Based on all 7 of their most recent companies above, what is the Secondary industry they work in:\n- Top 10 Technical Skills:\n- What technical language do they use most often?:\n- What technical language do they use second most often?:\n- What technical language do they use third most often?:\n- What software do they talk about using the most?:\n- What software do they talk about using the second most?:\n- What software do they talk about using the third most?:\n- What software do they talk about using the fourth most?:\n- What software do they talk about using the fifth most?:\n- What physical hardware do they talk about using the most?:\n- What physical hardware do they talk about using the second most?:\n- What physical hardware do they talk about using the third most?:\n- What physical hardware do they talk about using the fourth most?:\n- What physical hardware do they talk about using the fifth most?:\n- Based on their skills, put them in a primary technical category:\n- Based on their skills, put them in a subsidiary technical category:\n- Types of projects they have worked on:\n- Based on their skills, categories, certifications, and industries, determine what they specialize in:\n- Based on all this knowledge, write a summary of this candidate that could be sellable to an employer:\n- How long have they lived in the United States(numerical answer only):\n- Total years of professional experience (numerical answer only):\n- Average tenure at companies in years (numerical answer only):"}]}}
